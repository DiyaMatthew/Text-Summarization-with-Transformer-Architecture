# Text-Summarization-with-Transformer-Architecture
This project makes an investigation into Deep Learning based Text summarization using Transformer Architecture. 


There has been a rapid increase in the volume of text data in recent years. It is necessary to summarize this data in order to retrieve valuable knowledge within a reasonable period. In addition to saving valuable time, summarizing conveys the essence from which the reader can decide if they wish to investigate further. Text summarization involves the creation of concise and meaningful summaries of text from a variety of sources, including books, news articles, blog posts, and research papers. The process of manually converting the report to a summarized version is too time-consuming. As a result of enormous amounts of textual data being readily available, demand for automatic text summarization systems is on the rise. In almost every aspect of the internet, summaries are used to give readers a summary of an article, such as in e-commerce sites, search engines, and news sites. <br><br>
Text summarization approaches can be divided into two categories: Extractive summarization and Abstractive summarization. In extractive summarization, important sentences or phrases from the source documents are extracted and grouped for generating a summary without changing the original document. During abstract summarization, words and sentences are constructed, assembled in a clear, comprehensible fashion, and then only the key facts from the source text are added. In this way, abstract summarizing approaches are more sophisticated, accurate and computationally costly than extractive summarizing approaches.
